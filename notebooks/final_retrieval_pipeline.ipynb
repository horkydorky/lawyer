{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "704b0a0d",
   "metadata": {},
   "source": [
    "## Old/Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6f77fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HuggingFaceEmbeddings' from 'langchain.embeddings' (/home/jagannath/my_poc_law/MyPocketLawyer-AI-Powered-Legal-Aid-Assistant/venv/lib/python3.12/site-packages/langchain/embeddings/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'HuggingFaceEmbeddings' from 'langchain.embeddings' (/home/jagannath/my_poc_law/MyPocketLawyer-AI-Powered-Legal-Aid-Assistant/venv/lib/python3.12/site-packages/langchain/embeddings/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Missing GROQ_API_KEY in .env file\")\n",
    "\n",
    "# Paths and model setup\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \\\n",
    "    if os.path.basename(os.getcwd()) == \"notebooks\" else os.getcwd()\n",
    "CHROMA_DIR = os.path.join(ROOT_DIR, \"chroma_db\")\n",
    "\n",
    "EMBED_MODEL = \"BAAI/bge-large-en-v1.5\"\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "print(f\"Using Chroma DB from: {CHROMA_DIR}\")\n",
    "\n",
    "# Load vector store and embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL)\n",
    "db = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatGroq(\n",
    "    api_key=GROQ_API_KEY,\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.2,\n",
    "    max_tokens=512,\n",
    ")\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a helpful legal assistant. Use the context below to answer clearly and accurately.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "# Metadata-aware retriever\n",
    "class MetadataAwareRetriever(BaseRetriever):\n",
    "    model_config = {\"extra\": \"allow\"}  # allow custom attributes\n",
    "\n",
    "    def __init__(self, retriever, priority_keywords=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._retriever = retriever\n",
    "        self._priority_keywords = priority_keywords or []\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> list[Document]:\n",
    "        docs = self._retriever.get_relevant_documents(query)\n",
    "\n",
    "        def score_doc(doc: Document) -> float:\n",
    "            score = 0\n",
    "            chapter = doc.metadata.get(\"chapter\", \"\").lower()\n",
    "            for kw in self._priority_keywords:\n",
    "                if kw.lower() in chapter:\n",
    "                    score += 1\n",
    "            section = doc.metadata.get(\"section\", \"\")\n",
    "            if any(word.lower() in section.lower() for word in query.split()):\n",
    "                score += 0.5\n",
    "            return score\n",
    "\n",
    "        ranked_docs = sorted(docs, key=lambda d: score_doc(d), reverse=True)\n",
    "        return ranked_docs\n",
    "\n",
    "# Wrap retriever\n",
    "priority_keywords = [\"labor\", \"directive principles\", \"constitution\"]\n",
    "metadata_retriever = MetadataAwareRetriever(retriever, priority_keywords=priority_keywords)\n",
    "\n",
    "# RetrievalQA wrapper\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=metadata_retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078ec195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a sample query\n",
    "query = \"Who makes plans  on  any  matters  related  to  financial  powers  within  their  respective  jurisdictions.\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"\\nAnswer:\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"- {doc.metadata.get('source')} | Chapter: {doc.metadata.get('chapter')} | Section: {doc.metadata.get('section')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b9b82",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7273e",
   "metadata": {},
   "source": [
    "## New Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783ad008",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chromadb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m genai\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from google import genai\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"âŒ Missing GEMINI_API_KEY in .env\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "try:\n",
    "    BASE_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    BASE_DIR = Path.cwd()\n",
    "if BASE_DIR.name == \"notebooks\":\n",
    "    BASE_DIR = BASE_DIR.parent\n",
    "\n",
    "VECTORSTORE_DIR = BASE_DIR / \"chroma_db\"\n",
    "COLLECTION_NAME = \"legal_docs\"\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING\n",
    "# ============================================================\n",
    "\n",
    "def get_query_embedding(text):\n",
    "    \"\"\"Generate embedding for the query.\"\"\"\n",
    "    response = client.models.embed_content(\n",
    "        model=\"models/text-embedding-004\",\n",
    "        contents=[text]\n",
    "    )\n",
    "    return response.embeddings[0].values\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RETRIEVE FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def retrieve_top_k(query, k=5):\n",
    "    \"\"\"Retrieve top-k relevant clauses from Chroma.\"\"\"\n",
    "    client_chroma = chromadb.PersistentClient(path=str(VECTORSTORE_DIR))\n",
    "\n",
    "    try:\n",
    "        collection = client_chroma.get_collection(name=COLLECTION_NAME)\n",
    "    except Exception:\n",
    "        raise ValueError(f\"âŒ Collection '{COLLECTION_NAME}' not found in {VECTORSTORE_DIR}\")\n",
    "\n",
    "    query_emb = get_query_embedding(query)\n",
    "\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_emb],\n",
    "        n_results=k\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ” Query: {query}\\n\")\n",
    "    for i, (doc, meta, score) in enumerate(\n",
    "        zip(results[\"documents\"][0], results[\"metadatas\"][0], results[\"distances\"][0]),\n",
    "        start=1\n",
    "    ):\n",
    "        print(f\"--- Result {i} ---\")\n",
    "        print(f\"ðŸ“„ Source: {meta.get('document_title', 'Unknown')}\")\n",
    "        print(f\"ðŸ“˜ Part {meta.get('part_number', '')}: {meta.get('part_title', '')}\")\n",
    "        print(f\"ðŸ“œ Article {meta.get('article_number', '')}: {meta.get('article_title', '')}\")\n",
    "        print(f\"ðŸ”¢ Clause {meta.get('clause_index', '')}\")\n",
    "        print(f\"ðŸ“ Similarity: {score:.4f}\")\n",
    "        print(f\"ðŸ§¾ Text: {doc}\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# TEST SAMPLE QUERY\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What are the rights related to citizenship in Nepal?\"\n",
    "    retrieve_top_k(query, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea1def-ee2d-4e80-951a-9dc3b7599cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Using cached chromadb-1.3.4-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from chromadb) (2.10.3)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Using cached pybase64-1.4.2-cp313-cp313-macosx_10_13_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/anaconda3/lib/python3.13/site-packages (from chromadb) (2.1.3)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from chromadb) (4.12.2)\n",
      "INFO: pip is looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.3.3-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.2-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.3.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.2.2-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.2.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.2.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.1.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "INFO: pip is still looking at multiple versions of chromadb to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached chromadb-1.1.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.2 kB)\n",
      "  Using cached chromadb-1.0.21-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.20-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.19-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.18-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached chromadb-1.0.17-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.3 kB)\n",
      "  Using cached chromadb-1.0.16-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.4 kB)\n",
      "  Using cached chromadb-1.0.15-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.0 kB)\n",
      "  Using cached chromadb-1.0.13-cp39-abi3-macosx_10_12_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-7.0.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.12-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Using cached fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-1.0.11-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.10-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.9-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.8-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.7-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Using cached chroma_hnswlib-0.7.6.tar.gz (32 kB)\n",
      "  Installing build dependendone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Using cached chromadb-1.0.6-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.5-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.4-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.3-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.2-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-1.0.0-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.9 kB)\n",
      "  Using cached chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Using cached fastapi-0.121.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting chromadb\n",
      "  Using cached chromadb-0.6.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.6.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.21-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.20-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.17-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.16-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.12-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.10-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.9-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Using cached chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting numpy<2.0.0,>=1.22.5 (from chromadb)\n",
      "  Using cached numpy-1.26.4.tar.gz (15.8 MB)\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
